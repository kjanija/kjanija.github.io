<!doctype html><html lang=en><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Demographic Fairness for Loan Approval | Kjanija</title><link rel=stylesheet href=/css/style.css><link rel=stylesheet href=/css/syntax.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"\\[",right:"\\]",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1}],throwOnError:!1})})</script><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700;900&display=swap" rel=stylesheet></head><body><header><nav><a href=/ class=logo>–å–∞–Ω–∏—ò–∞.</a><ul><li><a href=/>Home</a></li><li><a href=/projects>Projects</a></li><li><a href=/cv.pdf>CV</a></li></ul></nav></header><main><article class=project-detail><header><h1>Demographic Fairness for Loan Approval</h1><div class=meta><div class=tags><span class=tag>RL</span>
<span class=tag>Safe & Verified AI</span>
<span class=tag>Shielded RL</span>
<span class=tag>Research</span></div><time class=post-date>Jan 2026</time></div></header><div class=content><p>You can also see it on <a href=https://github.com/kjanija/Safe-VerifiedAI>Github</a>.</p><h1 id=safe-verifiedai-normative-fairness-shield-for-rl->Safe-VerifiedAI: Normative Fairness Shield for RL üõ°Ô∏è</h1><figure><img src=/projects/fairnessrl/diagram_shield.png alt="Fig 1: System architecture"><figcaption><p>Fig 1: System architecture</p></figcaption></figure><p>A Reinforcement Learning framework demonstrating how to mitigate bias and enforce fairness constraints in AI agents using a real-time <strong>Normative Fairness Shield</strong>.</p><p>This project tackles a critical issue in AI: agents trained on biased historical data will naturally learn to discriminate against protected groups to maximize their baseline reward. By implementing a Constructive Oracle Shield, this framework actively monitors demographic parity, intervenes on unfair decisions, and uses reward shaping to teach the agent to be fair over time.</p><h2 id=key-features>Key Features</h2><ul><li><strong>Synthetic Biased Environment:</strong> Includes a custom <code>CreditDataGenerator</code> that simulates a credit scoring environment where protected groups have artificially lowered scores, tricking an unshielded agent into biased rejections.</li><li><strong>Constructive Oracle Shield:</strong> A stateful fairness monitor blocks unsafe actions and actively overrides biased rejections into fair approvals for qualified candidates.</li><li><strong>Reward Shaping Wrapper:</strong> A custom <code>Gymnasium</code> wrapper that penalizes the PPO agent when the shield intervenes, transferring the shield&rsquo;s &ldquo;fairness knowledge&rdquo; into the agent&rsquo;s core policy.</li></ul><h2 id=how-it-works>How It Works</h2><h3 id=the-normative-fairness-shield>The Normative Fairness Shield</h3><p>To enforce fairness constraints, the shield monitors the agent&rsquo;s actions in real-time to enforce <strong>Demographic Parity</strong>. This mandates that the approval rate for a protected group must not fall below a certain threshold compared to the majority group.</p><p>At each timestep, the shield calculates the current approval rates. If the ratio falls below the threshold, the shield intervenes. Specifically, it acts as a <em>Constructive Oracle Shield</em>: it overrides the agent&rsquo;s decision from <code>Reject</code> to <code>Approve</code> if and only if:</p><ol><li><strong>Fairness Violation:</strong> Demographic parity is violated.</li><li><strong>Protected Status:</strong> The applicant belongs to a protected demographic.</li><li><strong>Qualification:</strong> The applicant is actually qualified.</li></ol><h3 id=reward-shaping-via-the-shield-wrapper>Reward Shaping via the Shield Wrapper</h3><p>The shield is integrated into the RL environment using a custom <code>ShieldEnvWrapper</code>.
When the wrapper intercepts a biased action and the shield intervenes, it applies a penalty to the agent&rsquo;s reward.</p><p>If the standard reward is $R(s,a)$, the shaped reward $R&rsquo;(s,a)$ becomes:
$$R&rsquo;(s,a) = R(s,a&rsquo;) - \lambda \cdot \mathbf{1}(\text{Intervention})$$</p><p>This teaches the agent that attempting unfair rejections results in a lower net reward than autonomously making the fair decision. Over time, the agent should internalize the fairness constraints, reducing the need for shield interventions.</p><h2 id=some-results>Some results</h2><figure><img src=/projects/fairnessrl/agent_comparison_metrics.png alt="Fig 2: Unshielded vs Shielded RL agent comparison"><figcaption><p>Fig 2: Unshielded vs Shielded RL agent comparison</p></figcaption></figure></div></article></main><footer><p>&copy; 2026 Kjanija Mersimoski.</p></footer></body></html>